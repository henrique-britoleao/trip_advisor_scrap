{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AYtzqiFVEDWw"
   },
   "source": [
    "#Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "mSZW86_D08Pw"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'utils.loader_utils'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-4944d3972d26>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# import utils functions and classes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mDataLoader\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTADataLoader\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mTextPreprocessing\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mTextPreprocessor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLemmatizeCorpus\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLemmatizeCorpus\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Documents/X-HEC/Y1/Capgemini/trip_advisor_scrap/Deliverable_2/DataLoader.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcalendar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mread_jl_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextract_details\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mget_resto_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvert_date\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocessing_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlanguage_filter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'utils.loader_utils'"
     ]
    }
   ],
   "source": [
    "# add path\n",
    "import sys\n",
    "sys.path.append('../Deliverable_2/')\n",
    "\n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from numpy.random import randint\n",
    "import seaborn as sns\n",
    "from collections import Counter, OrderedDict\n",
    "import cld2\n",
    "\n",
    "# import utils functions and classes\n",
    "from DataLoader import TADataLoader\n",
    "from TextPreprocessing import TextPreprocessor\n",
    "from LemmatizeCorpus import LemmatizeCorpus\n",
    "from stem_corpus import stem_corpus\n",
    "from Embeddor import Embeddor\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from ast import literal_eval\n",
    "\n",
    "import gensim.downloader as api\n",
    "\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rcParams[\"figure.figsize\"] = (10, 6)\n",
    "sns.set_palette(\"husl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/tensorflow_addons/utils/ensure_tf_install.py:67: UserWarning: Tensorflow Addons supports using Python ops for all Tensorflow versions above or equal to 2.3.0 and strictly below 2.5.0 (nightly versions are not supported). \n",
      " The versions of TensorFlow you are currently using is 2.2.0 and is not supported. \n",
      "Some things might work, some things might not.\n",
      "If you were to encounter a bug, do not file an issue.\n",
      "If you want to make sure you're using a tested and supported configuration, either change the TensorFlow version or the TensorFlow Addons's version. \n",
      "You can find the compatibility matrix in TensorFlow Addon's readme:\n",
      "https://github.com/tensorflow/addons\n",
      "  UserWarning,\n"
     ]
    },
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'keras_tensor' from 'tensorflow.python.keras.engine' (/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-86eccee498ab>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_addons/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;31m# Local project imports\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mactivations\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_addons/activations/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\"\"\"Additional activation functions.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgelu\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mgelu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhardshrink\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mhardshrink\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactivations\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlisht\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mlisht\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_addons/activations/gelu.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow_addons\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtypes\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdistutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mversion\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mLooseVersion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.7/site-packages/tensorflow_addons/utils/types.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;31m# TODO: Remove once https://github.com/tensorflow/tensorflow/issues/44613 is resolved\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras_tensor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'keras_tensor' from 'tensorflow.python.keras.engine' (/opt/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/engine/__init__.py)"
     ]
    }
   ],
   "source": [
    "import tensorflow_addons"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vvYZ5F-cM6Ho"
   },
   "source": [
    "#Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TTrQtpHx1Kvu"
   },
   "outputs": [],
   "source": [
    "loader = TADataLoader()\n",
    "df_restos, df_reviews = loader.load_restos(drop_duplicates=True),\\\n",
    "                        loader.load_reviews(drop_duplicates=True)\n",
    "#df_reviews = df_reviews.iloc[:5000]\n",
    "preprocessor = TextPreprocessor(df_reviews, column_to_clean='review_content')\n",
    "preprocessor.transform(n_grams=False)\n",
    "corpus = preprocessor.corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MB2PToUU1qSM"
   },
   "source": [
    "#LSI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N6c8GEQQ3_71"
   },
   "source": [
    "We first perform LSI with respect to the reviews on the the two first dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 201
    },
    "id": "yv38a53r1r0w",
    "outputId": "769db82e-5891-43a1-d659-703addbcadbc"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus) #use our custom class to compute the embedding\n",
    "embeddor.transform(vec_method=\"tfidf\", how=\"SVD\", n=2)\n",
    "lsi = embeddor.review_embedding\n",
    "lsi['corpus'] = corpus  #add columns to link the embedding to the review\n",
    "lsi['rating'] = df_reviews['review_rating']\n",
    "lsi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gs15-4xB43MH"
   },
   "source": [
    "Now, we compute LSI with as many dimensions as needed to explain a given percentage of the variance. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 646
    },
    "id": "a9mzD4M94qqj",
    "outputId": "4dc2882c-ecdd-454e-cee4-bc87bbd4e43f"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus)\n",
    "embeddor.transform(vec_method=\"tfidf\", how=\"SVD\", n=\"n_opt\", threshold=0.5)\n",
    "lsi = embeddor.review_embedding\n",
    "lsi['corpus'] = corpus\n",
    "lsi['rating'] = df_reviews['review_rating']\n",
    "lsi.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rOZMWHDcZsUa"
   },
   "source": [
    "#Word2vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1MU6GH_LWZ8U"
   },
   "source": [
    "Now we will use the word2vec embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "75eHcKCZ_eqX",
    "outputId": "8c6892c6-f891-426b-f2a4-e31de862cbb1"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus)\n",
    "embeddor.transform(vec_method=\"word2vec\", how=\"PCA\", n=\"n_opt\", threshold=0.95)\n",
    "word2vec_embed = embeddor.review_embedding\n",
    "word2vec_model = embeddor.model\n",
    "word2vec_embed['corpus'] = corpus\n",
    "word2vec_embed['rating'] = df_reviews['review_rating']\n",
    "word2vec_embed.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J2ZQSDrja9e0"
   },
   "source": [
    "Thanks to the word2vec embedding we can see the proximity between terms in our dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eiWancMhaq1S",
    "outputId": "7c8a0fe0-3c83-48e9-ec98-dda854e44d98"
   },
   "outputs": [],
   "source": [
    "word2vec_model.wv.most_similar(\"waiter\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kBr_LeCpdTDM"
   },
   "source": [
    "As we observe what appears to be waiters' names, the embedding is quite accurate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sRDL435wbVA7"
   },
   "source": [
    "#Fasttext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iglpZsXeWlMA"
   },
   "source": [
    "Thnaks to our class we can also use a fattext embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 255
    },
    "id": "MlNv2gUzbYy9",
    "outputId": "51efc5a1-df32-4051-f15a-e027542052e4"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus)\n",
    "embeddor.transform(vec_method=\"fasttext\", how=\"PCA\", n=\"n_opt\", threshold=0.95)\n",
    "fasttext_embed = embeddor.review_embedding\n",
    "fasttext_model = embeddor.model\n",
    "fasttext_embed['corpus'] = corpus\n",
    "fasttext_embed['rating'] = df_reviews['review_rating']\n",
    "fasttext_embed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ps0SK-5FccY8",
    "outputId": "4bc7fd4a-f288-48e3-b44d-11c379671e67"
   },
   "outputs": [],
   "source": [
    "fasttext_model.wv.most_similar(\"waiter\", topn=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Badyhee0WuR6"
   },
   "source": [
    "The most similar words appear to be slightly less accurate thant the ones produced by the word2vec method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rYz6ZfgScvG1"
   },
   "source": [
    "#Data augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MSPTr3x_At3N"
   },
   "source": [
    "We observe that our dataset is not balanced which isn't a good point if we want to cluster the different topics or if we want to build a classification model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "JL4gX8G_YytN",
    "outputId": "9d30271f-aa1b-4f89-e196-aabdf829eb0f"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='review_rating', data=df_reviews)\n",
    "plt.title('Number of reviews per rating')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel(' ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "d3OeCSCddSf3"
   },
   "source": [
    "To overcome the skewness of our dataset we perform data augmentation. In order to achieve this we create new reviews with similar terms (according to the general word2vec pretrained model). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_U2Ht71uXQhU"
   },
   "source": [
    "At this point we can either load the augmented corpus that has been obtained or rerun the following steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f-NVkP4Xut1"
   },
   "outputs": [],
   "source": [
    "#load augmented corpus\n",
    "path = 'balanced_corpus.txt'\n",
    "with open(path, 'r') as f:\n",
    "  corpus_augmented = literal_eval(f.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeeOuL1iZIHY"
   },
   "source": [
    "##Creating augmented corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dFL6FqNnbn0Y",
    "outputId": "5697d208-1bf3-4203-cee5-2a2ff567f6aa"
   },
   "outputs": [],
   "source": [
    "#load pretrained model for augmentation\n",
    "wv = api.load('word2vec-google-news-300')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "thfiPZ_qf5NL"
   },
   "outputs": [],
   "source": [
    "#corpus per rating\n",
    "for i in range(1,6):\n",
    "    exec(f'r{i} = df_reviews[df_reviews.loc[:,\"review_rating\"]==i]')\n",
    "    exec(f\"preprocessor = TextPreprocessor(r{i}, column_to_clean='review_content')\")\n",
    "    preprocessor.transform(n_grams=False)\n",
    "    exec(f'corpus{i} = preprocessor.corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dK_eH4UVqnY8"
   },
   "outputs": [],
   "source": [
    "def similar(corp):\n",
    "    for i in range(len(corp)):\n",
    "        print(i)                                      \n",
    "        for j in range(len(corp[i])):\n",
    "            n = randint(2)\n",
    "            try:\n",
    "                corp[i][j] = wv.most_similar(corp[i][j], topn=3)[n][0]\n",
    "            except:\n",
    "                continue\n",
    "    return corp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ICGhPFGsjG8T"
   },
   "outputs": [],
   "source": [
    "#we augment the number of reviews for ratings 1 and 2\n",
    "corpus1_augmented = corpus1.copy()\n",
    "corpus1_augmented = similar(corpus1_augmented)\n",
    "corpus2_augmented = corpus2.copy()\n",
    "corpus2_augmented = similar(corpus2_augmented)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7SBl2BBLTf2I"
   },
   "outputs": [],
   "source": [
    "#create a balanced datset\n",
    "corpus_augmented = corpus1 + corpus1_augmented[1:36] + corpus2\\\n",
    "                   + corpus2_augmented + corpus3[:110] + corpus4[:110]\\\n",
    "                   + corpus5[:110]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gdKkShHTZMxQ"
   },
   "source": [
    "##Augmented corpus results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "ApulvO0bLmLO",
    "outputId": "b6b00d05-fc4c-4ac1-835c-64556a708623"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus_augmented)\n",
    "embeddor.transform(vec_method=\"tfidf\", how=\"SVD\", n=\"n_opt\", threshold=0.5)\n",
    "lsi = embeddor.review_embedding\n",
    "lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EEmJ5KlQahCJ"
   },
   "outputs": [],
   "source": [
    "ratings = [1]*104 + [2]*116 + [3]*110 + [4]*110 + [5]*110"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 629
    },
    "id": "6nL7WHkccYeJ",
    "outputId": "44606920-0256-4d22-dd9a-c3b123efc31b"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus_augmented)\n",
    "embeddor.transform(vec_method=\"tfidf\", how=\"SVD\", n=\"n_opt\", threshold=0.5)\n",
    "lsi = embeddor.review_embedding\n",
    "lsi['corpus'] = corpus_augmented\n",
    "lsi['rating'] = ratings\n",
    "lsi.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 404
    },
    "id": "54poCxBaUV4u",
    "outputId": "8dd344a0-f5c8-4cd6-b578-d140d115ca72"
   },
   "outputs": [],
   "source": [
    "sns.countplot(x='rating', data=lsi)\n",
    "plt.title('Number of reviews per rating after data augmentation')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel(' ')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sMGCl4BhDBfZ"
   },
   "source": [
    "Let's see how the different topics are linked to the quality of the reviews (for the first 25 directions):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gk3iwuv6a4Kf",
    "outputId": "7f268fb0-863a-4d49-bd7b-780ba6501187"
   },
   "outputs": [],
   "source": [
    "for i in range(25):\n",
    "    rat_list = []\n",
    "    lsi[f'SV{i+1}'] = np.abs(lsi[f'SV{i+1}'])\n",
    "    top_words = lsi.sort_values(f'SV{i+1}', ascending=False).index[:20]\n",
    "    print(f\"Average rating for topic {i} is : \")\n",
    "    for ind in list(top_words):\n",
    "        rat_list.append(ratings[ind])\n",
    "    print(sum(rat_list)/20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_0HVHgCBUlD"
   },
   "source": [
    "We can now visualize how the quality of a review is related to a topic. In the following example the topic 1 is mostly associated with good reviews while the second topic is mostly associated with bad reviews. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 623
    },
    "id": "WhxlWJpq8p3A",
    "outputId": "081ce043-efaf-4f5d-9ab6-374a35a814f5"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))\n",
    "\n",
    "colors = ['red', 'orange', 'yellow', 'yellowgreen', 'green']\n",
    "\n",
    "for val in lsi['rating'].unique():\n",
    "    topic_1 = np.abs(lsi[lsi['rating']==val]['SV1'].values)\n",
    "    topic_2 = np.abs(lsi[lsi['rating']==val]['SV66'].values)\n",
    "    color = colors[val-1]\n",
    "    ax.scatter(topic_1, topic_2, alpha=0.7, label=val, color=color)\n",
    "    \n",
    "ax.set_xlabel('First Topic')\n",
    "ax.set_ylabel('Second Topic')\n",
    "ax.axvline(linewidth=0.5)\n",
    "ax.axhline(linewidth=0.5)\n",
    "ax.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k5UZYUhWCL8u"
   },
   "source": [
    "Let's see what are the top reviews associated with each topic. We observe that \"food\" is often mentioned in the reviews associated with the first topics while the service appears several times in the reviews associated with the second topic. We conclude that food is the differentiating factor for restaurants and bars while service is only a requirement. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7MKwyAw3bjf2",
    "outputId": "aa06958b-1668-4b1d-a91c-e90419edc71d"
   },
   "outputs": [],
   "source": [
    "for i in [0, 65]:\n",
    "    rat_list = []\n",
    "    lsi[f'SV{i+1}'] = np.abs(lsi[f'SV{i+1}'])\n",
    "    top_words = lsi.sort_values(f'SV{i+1}', ascending=False).index[:5]\n",
    "    print(f\"Top review for topic {i} is: \")\n",
    "    for ind in list(top_words):\n",
    "        print(lsi.corpus[ind])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ssS-PsilOMur"
   },
   "source": [
    "#Classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qPSGLQjgo09R"
   },
   "source": [
    "##LSI embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ftOKyB69o3iR"
   },
   "source": [
    "###Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "W7lcKxpbRUkH",
    "outputId": "d1dbe20c-c02f-43b6-d2e7-196a436e126a"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus_augmented)\n",
    "embeddor.transform(vec_method=\"tfidf\", how=\"SVD\", n=\"n_opt\", threshold=0.5)\n",
    "lsi = embeddor.review_embedding\n",
    "lsi['rating'] = ratings\n",
    "lsi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JWSiVBqgOPOY",
    "outputId": "e4a05f4a-1bec-4d98-8f51-7e7a5ad1ceff"
   },
   "outputs": [],
   "source": [
    "#prep df \n",
    "lsi.dropna(inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(lsi.iloc[:, :-1],\n",
    "                                                    lsi.iloc[:, -1], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    shuffle=True)\n",
    "# check distribution of ratings\n",
    "print(\"Value counts for Train reviews\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Value counts for Test resviews\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mXRwbg_UOQIs",
    "outputId": "7bbd02bf-16f9-46e2-976d-fbda093d0732"
   },
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "logreg.fit(X_train, y_train)\n",
    "# cross validation\n",
    "scores_log = cross_val_score(logreg, X_train, y_train, cv = 10, \n",
    "                            scoring='f1_weighted')\n",
    "print('Cross-validation scores:{}'.format(scores_log))\n",
    "avg_score_log = np.mean(scores_log)\n",
    "print('Average cross-validation score:{}'.format(avg_score_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "dwlWcrQ7OUSx",
    "outputId": "0015f2a1-d7e3-4200-b757-34df320851ad"
   },
   "outputs": [],
   "source": [
    "#classification report \n",
    "pred_logreg = logreg.predict(X_test)\n",
    "print(classification_report(y_test, pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 421
    },
    "id": "9zd41m4eOWon",
    "outputId": "be755986-0299-4bcd-86a5-c2ad330ec538"
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "data = confusion_matrix(y_test, pred_logreg, normalize='true')\n",
    "df_cm = pd.DataFrame(data, columns=[1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
    "df_cm.index.name = 'True label'\n",
    "df_cm.columns.name = 'Predicted label'\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.title('Confusion Matrix')\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 12}, fmt='.1g')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UgqhQSCMokau"
   },
   "source": [
    "###Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NYgXbzh_m3Mc",
    "outputId": "cde8f592-520f-4ef3-d9a0-6edc6a3b4ed9"
   },
   "outputs": [],
   "source": [
    "#random forest classifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "scores_rf = cross_val_score(rf, X_train, y_train, cv = 10, \n",
    "                            scoring='f1_weighted')\n",
    "print('Cross-validation scores:{}'.format(scores_rf))\n",
    "avg_score_rf = np.mean(scores_rf)\n",
    "print('Average cross-validation score:{}'.format(avg_score_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rqKzfIe7nHcE",
    "outputId": "2a2269b2-6127-4bd2-a91b-89d3792ace10"
   },
   "outputs": [],
   "source": [
    "pred_labels_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, pred_labels_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "LfnpZO69nJAa",
    "outputId": "792143ab-6953-4e67-9e1c-8bae305761a4"
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "data = confusion_matrix(y_test, pred_labels_rf, normalize='true')\n",
    "df_cm = pd.DataFrame(data, columns=[1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
    "\n",
    "df_cm.index.name = 'True label'\n",
    "df_cm.columns.name = 'Predicted label'\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.title('Normalized confusion matrix')\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 12}, fmt='.1g'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SF62sYc3o6_1"
   },
   "source": [
    "The random forest classifier shows better result than the logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BlQt91M_mjrP"
   },
   "source": [
    "##Word2vec embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nNyldlb1mtMV"
   },
   "source": [
    "We use a random forest classifier with the word2vec embedding as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "AFjerKNZiulM",
    "outputId": "17129220-8cc2-42e9-f22d-c6963feaf3fd"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus_augmented)\n",
    "embeddor.transform(vec_method=\"word2vec\", how=\"PCA\", n=100) #n_opt wasn't offering good results\n",
    "word2vec_embed = embeddor.review_embedding\n",
    "word2vec_embed['rating'] = ratings\n",
    "word2vec_embed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I5dd_3AJjHr2",
    "outputId": "db55cc9f-8664-4f29-fea6-2e4af12c2a5f"
   },
   "outputs": [],
   "source": [
    "word2vec_embed.dropna(inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(word2vec_embed.iloc[:, :-1],\n",
    "                                                    word2vec_embed.iloc[:, -1], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    shuffle=True)\n",
    "# check distribution of ratings\n",
    "print(\"Value counts for Train reviews\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Value counts for Test resviews\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4akZfLWZlOXg",
    "outputId": "643333d8-9894-4808-ef38-c3d9c634986f"
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "scores_rf = cross_val_score(rf, X_train, y_train, cv = 10, \n",
    "                            scoring='f1_weighted')\n",
    "print('Cross-validation scores:{}'.format(scores_rf))\n",
    "avg_score_rf = np.mean(scores_rf)\n",
    "print('Average cross-validation score:{}'.format(avg_score_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VMReYkHbmKwJ",
    "outputId": "b6beb87f-ee48-4128-a271-de946d73cb78"
   },
   "outputs": [],
   "source": [
    "#classification reports\n",
    "pred_labels_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, pred_labels_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "JWIezYhXmR0h",
    "outputId": "eeb165de-d773-46d0-f629-bdceb8a8e71a"
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "data = confusion_matrix(y_test, pred_labels_rf, normalize='true')\n",
    "df_cm = pd.DataFrame(data, columns=[1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
    "\n",
    "df_cm.index.name = 'True label'\n",
    "df_cm.columns.name = 'Predicted label'\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.title('Normalized confusion matrix')\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 12}, fmt='.1g'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CIlPlIpIneBL"
   },
   "source": [
    "##Fasttext Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VD8XQG0knjE_"
   },
   "source": [
    "We use a random forest classifier with the fasstext embedding as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 450
    },
    "id": "uXJ8BABJnlj-",
    "outputId": "944429ec-765a-4ed6-926e-5ae3bf36e639"
   },
   "outputs": [],
   "source": [
    "embeddor = Embeddor(corpus=corpus_augmented)\n",
    "embeddor.transform(vec_method=\"fasttext\", how=\"PCA\", n=100) #n_opt wasn't offering good results\n",
    "fasttext = embeddor.review_embedding\n",
    "fasttext['rating'] = ratings\n",
    "fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "814tBxbbnxtV",
    "outputId": "73483a6b-e36b-492c-f47c-16e066e2d27c"
   },
   "outputs": [],
   "source": [
    "fasttext.dropna(inplace=True)\n",
    "X_train, X_test, y_train, y_test = train_test_split(fasttext.iloc[:, :-1],\n",
    "                                                    fasttext.iloc[:, -1], \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=0, \n",
    "                                                    shuffle=True)\n",
    "# check distribution of ratings\n",
    "print(\"Value counts for Train reviews\")\n",
    "print(y_train.value_counts())\n",
    "print(\"Value counts for Test resviews\")\n",
    "print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-dhUQOXmoImX",
    "outputId": "857bb28b-c84a-4041-93d5-871f9135492b"
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(X_train, y_train)\n",
    "\n",
    "scores_rf = cross_val_score(rf, X_train, y_train, cv = 10, \n",
    "                            scoring='f1_weighted')\n",
    "print('Cross-validation scores:{}'.format(scores_rf))\n",
    "avg_score_rf = np.mean(scores_rf)\n",
    "print('Average cross-validation score:{}'.format(avg_score_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ykn8GaQtn80g",
    "outputId": "84977ffe-14ff-49fd-a5b5-07929806f95f"
   },
   "outputs": [],
   "source": [
    "#classification reports\n",
    "pred_labels_rf = rf.predict(X_test)\n",
    "print(classification_report(y_test, pred_labels_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 415
    },
    "id": "SF6R7qZBoPqB",
    "outputId": "ac503ad9-b236-4b58-c988-66770d9de07d"
   },
   "outputs": [],
   "source": [
    "#confusion matrix\n",
    "data = confusion_matrix(y_test, pred_labels_rf, normalize='true')\n",
    "df_cm = pd.DataFrame(data, columns=[1, 2, 3, 4, 5], index=[1, 2, 3, 4, 5])\n",
    "\n",
    "df_cm.index.name = 'True label'\n",
    "df_cm.columns.name = 'Predicted label'\n",
    "plt.figure(figsize = (9, 6))\n",
    "plt.title('Normalized confusion matrix')\n",
    "sns.set(font_scale=1.2) \n",
    "sns.heatmap(df_cm, cmap=\"Blues\", annot=True, annot_kws={\"size\": 12}, fmt='.1g'); "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uANo-S3SpJth"
   },
   "source": [
    "#Final remark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tu9_I0EjpMOD"
   },
   "source": [
    "None of our classifier is showing convincing results. However we are aware that several points can be improved: more data can be scrapped, data augmentation should be performed at a higher scale, a deep learning method could outperform the ones we have shown.\n",
    "\n",
    "It is interesting to note that even if the dataset is balanced between the classes, it appears easier to predict accurately good reviews (rated 4 or 5) than negative ones (rated 1 or 2)."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Deliverable_3.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
